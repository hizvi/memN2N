{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1497,
     "status": "ok",
     "timestamp": 1556752144935,
     "user": {
      "displayName": "Hasan Rizvi",
      "photoUrl": "",
      "userId": "12377090762076158584"
     },
     "user_tz": 300
    },
    "id": "_5VJVJOqFsN5",
    "outputId": "fb00f226-1e4c-4539-eb9d-e4869ac5ea2f"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Embedding, Input, Dropout, Lambda, Flatten\n",
    "from keras.layers import Dot, Activation, Softmax, Add, Multiply, Permute\n",
    "from keras.layers import dot, add, multiply\n",
    "\n",
    "from keras.engine.topology import Layer\n",
    "\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# from src.util import *\n",
    "\n",
    "from keras.backend import variable, transpose, reshape, gather\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "import tarfile\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7O1EdrUWGrfs"
   },
   "outputs": [],
   "source": [
    "def tokenize(sent):\n",
    "    '''Return the tokens of a sentence including punctuation.\n",
    "    >>> tokenize('Bob dropped the apple. Where is the apple?')\n",
    "    ['Bob', 'dropped', 'the', 'apple', '.', 'Where', 'is', 'the', 'apple', '?']\n",
    "    '''\n",
    "    return [x.strip() for x in re.split(r'(\\W+)?', sent) if x.strip()]\n",
    "\n",
    "\n",
    "def parse_stories(lines, only_supporting=False):\n",
    "    '''Parse stories provided in the bAbi tasks format\n",
    "    If only_supporting is true, only the sentences\n",
    "    that support the answer are kept.\n",
    "    '''\n",
    "    data = []\n",
    "    story = []\n",
    "    for line in lines:\n",
    "        line = line.decode('utf-8').strip()\n",
    "        nid, line = line.split(' ', 1)\n",
    "        nid = int(nid)\n",
    "        if nid == 1:\n",
    "            story = []\n",
    "        if '\\t' in line:\n",
    "            q, a, supporting = line.split('\\t')\n",
    "            q = tokenize(q)\n",
    "            if only_supporting:\n",
    "                # Only select the related substory\n",
    "                supporting = map(int, supporting.split())\n",
    "                substory = [story[i - 1] for i in supporting]\n",
    "            else:\n",
    "                # Provide all the substories\n",
    "                substory = [x for x in story if x]\n",
    "            data.append((substory, q, a))\n",
    "            story.append('')\n",
    "        else:\n",
    "            sent = tokenize(line)\n",
    "            story.append(sent)\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_stories(f, only_supporting=False, max_length=None):\n",
    "    '''Given a file name, read the file,\n",
    "    retrieve the stories,\n",
    "    and then convert the sentences into a single story.\n",
    "    If max_length is supplied,\n",
    "    any stories longer than max_length tokens will be discarded.\n",
    "    '''\n",
    "    data = parse_stories(f.readlines(), only_supporting=only_supporting)\n",
    "    flatten = lambda data: reduce(lambda x, y: x + y, data)\n",
    "    data = [(flatten(story), q, answer) for story, q, answer in data\n",
    "            if not max_length or len(flatten(story)) < max_length]\n",
    "    return data\n",
    "\n",
    "\n",
    "def vectorize_stories(data, word_idx, story_maxlen, query_maxlen):\n",
    "    inputs, queries, answers = [], [], []\n",
    "    for story, query, answer in data:\n",
    "        inputs.append([word_idx[w] for w in story])\n",
    "        queries.append([word_idx[w] for w in query])\n",
    "        answers.append(word_idx[answer])\n",
    "    return (pad_sequences(inputs, maxlen=story_maxlen),\n",
    "            pad_sequences(queries, maxlen=query_maxlen),\n",
    "            np.array(answers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9SIR4LwoHCCN"
   },
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "# files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2074,
     "status": "ok",
     "timestamp": 1556752148314,
     "user": {
      "displayName": "Hasan Rizvi",
      "photoUrl": "",
      "userId": "12377090762076158584"
     },
     "user_tz": 300
    },
    "id": "e_aKSz3dH4cI",
    "outputId": "e03c7ae8-414e-4464-aa8f-ef569a9ee31a"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    path = get_file('babi-tasks-v1-2.tar.gz',\n",
    "                    origin='https://s3.amazonaws.com/text-datasets/'\n",
    "                           'babi_tasks_1-20_v1-2.tar.gz')\n",
    "except:\n",
    "    print('Error downloading dataset, please download it manually:\\n'\n",
    "          '$ wget http://www.thespermwhale.com/jaseweston/babi/tasks_1-20_v1-2'\n",
    "          '.tar.gz\\n'\n",
    "          '$ mv tasks_1-20_v1-2.tar.gz ~/.keras/datasets/babi-tasks-v1-2.tar.gz')\n",
    "    raise\n",
    "\n",
    "\n",
    "challenges = {\n",
    "    # QA1 with 10,000 samples\n",
    "    'qa1': 'tasks_1-20_v1-2/en-10k/qa1_single-supporting-fact_{}.txt',\n",
    "    'qa2': 'tasks_1-20_v1-2/en-10k/qa2_two-supporting-facts_{}.txt',\n",
    "    'qa3': 'tasks_1-20_v1-2/en-10k/qa3_three-supporting-facts_{}.txt',\n",
    "    'qa4': 'tasks_1-20_v1-2/en-10k/qa4_two-arg-relations_{}.txt',\n",
    "    'qa5': 'tasks_1-20_v1-2/en-10k/qa5_three-arg-relations_{}.txt',\n",
    "    'qa6': 'tasks_1-20_v1-2/en-10k/qa6_yes-no-questions_{}.txt',\n",
    "    'qa7': 'tasks_1-20_v1-2/en-10k/qa7_counting_{}.txt',\n",
    "    'qa8': 'tasks_1-20_v1-2/en-10k/qa8_lists-sets_{}.txt',\n",
    "    'qa9': 'tasks_1-20_v1-2/en-10k/qa9_simple-negation_{}.txt',\n",
    "    'qa10': 'tasks_1-20_v1-2/en-10k/qa10_indefinite-knowledge_{}.txt',\n",
    "    'qa11': 'tasks_1-20_v1-2/en-10k/qa11_basic-coreference_{}.txt',\n",
    "    'qa12': 'tasks_1-20_v1-2/en-10k/qa12_conjunction_{}.txt',\n",
    "    'qa13': 'tasks_1-20_v1-2/en-10k/qa13_compound-coreference_{}.txt',\n",
    "    'qa14': 'tasks_1-20_v1-2/en-10k/qa14_time-reasoning_{}.txt',\n",
    "    'qa15': 'tasks_1-20_v1-2/en-10k/qa15_basic-deduction_{}.txt',\n",
    "    'qa16': 'tasks_1-20_v1-2/en-10k/qa16_basic-induction_{}.txt',\n",
    "    'qa17': 'tasks_1-20_v1-2/en-10k/qa17_positional-reasoning_{}.txt',\n",
    "    'qa18': 'tasks_1-20_v1-2/en-10k/qa18_size-reasoning_{}.txt',\n",
    "    'qa19': 'tasks_1-20_v1-2/en-10k/qa19_path-finding_{}.txt',\n",
    "    'qa20': 'tasks_1-20_v1-2/en-10k/qa20_agents-motivations_{}.txt',\n",
    "}\n",
    "\n",
    "challenge_type = 'qa{}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zrNtmWFdijxZ"
   },
   "outputs": [],
   "source": [
    "class MemN2NBlock(Layer): \n",
    "    def __init__(self, output_dim):\n",
    "        super(MemN2NBlock, self).__init__()\n",
    "        \n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        # layer operations\n",
    "        self.input_memory = Dot(axes=(-1))\n",
    "        self.input_representation = Softmax()\n",
    "        self.permute_weights = Permute((2,1))\n",
    "        self.output_memory = Dot(axes=(2,1))\n",
    "        self.h_mapping = self.add_weight(\n",
    "                name='H',\n",
    "                shape=(self.output_dim[2],output_dim[2]),\n",
    "                initializer='glorot_normal',\n",
    "                trainable=True\n",
    "        )\n",
    "        self.new_u = Add()\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        m = self.input_memory([inputs[0], inputs[1]])\n",
    "        p = self.input_representation(m)\n",
    "        # print('p.shape: ', p.shape)\n",
    "        # p = self.permute_weights(p) \n",
    "        p = reshape(p, [-1, p.shape[2], p.shape[1]])\n",
    "        # print('p.shape: ', p.shape)\n",
    "        c = self.output_memory([p, inputs[2]])\n",
    "        \n",
    "        mapped_u = K.dot(inputs[1], self.h_mapping)\n",
    "        \n",
    "        return self.new_u([c, mapped_u])\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        super(MemN2NBlock, self).build(input_shape)\n",
    "        \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return self.output_dim\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xsoBdPPuiT1f"
   },
   "outputs": [],
   "source": [
    "def build_model(story_maxlen, query_maxlen, vocab_size):\n",
    "    print('MEM N2N model')\n",
    "\n",
    "    HOPS = 3\n",
    "\n",
    "    sentences = Input((story_maxlen,))\n",
    "    question = Input((query_maxlen,))\n",
    "\n",
    "    A = Embedding(vocab_size, 64, na)(sentences)\n",
    "    B = Embedding(vocab_size, 64)(question)\n",
    "    C = Embedding(vocab_size, 64)(sentences)\n",
    "\n",
    "    u = B\n",
    "    u_shape = tuple(map(lambda x: x.value, u.shape))\n",
    "\n",
    "    for i in range(HOPS):\n",
    "        u = MemN2NBlock(output_dim=u_shape)([A, u, C])\n",
    "\n",
    "    # u = Lambda(lambda x: K.sum(x, axis=1))(u) \n",
    "    u = Flatten()(u)\n",
    "\n",
    "    result = Dense(vocab_size, activation='softmax', use_bias=False)(u)\n",
    "\n",
    "    print(result.shape)\n",
    "\n",
    "\n",
    "    MemN2Nmodel = Model(inputs=[sentences, question], outputs=result)\n",
    "    MemN2Nmodel.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return MemN2Nmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 27070
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1407993,
     "status": "ok",
     "timestamp": 1556753559677,
     "user": {
      "displayName": "Hasan Rizvi",
      "photoUrl": "",
      "userId": "12377090762076158584"
     },
     "user_tz": 300
    },
    "id": "JusaVJM1FsN_",
    "outputId": "52be0e25-7695-4854-a60a-ea643d94574f"
   },
   "outputs": [],
   "source": [
    "# Tasks 1 to 5\n",
    "\n",
    "histories = []\n",
    "for i in range(1, 6):\n",
    "    challenge = challenges[challenge_type.format(i)]\n",
    "  \n",
    "    print('Extracting stories for the challenge:', challenge_type.format(i))\n",
    "    print(challenge.format(''))\n",
    "  \n",
    "    with tarfile.open(path) as tar:\n",
    "        train_stories = get_stories(tar.extractfile(challenge.format('train')))\n",
    "        test_stories = get_stories(tar.extractfile(challenge.format('test')))\n",
    "\n",
    "    # Building vocabulary\n",
    "    vocab = set()\n",
    "    for story, q, answer in train_stories + test_stories:\n",
    "        vocab |= set(story + q + [answer])\n",
    "    vocab = sorted(vocab)\n",
    "\n",
    "    # Reserve 0 for masking via pad_sequences\n",
    "    vocab_size = len(vocab) + 1\n",
    "    story_maxlen = max(map(len, (x for x, _, _ in train_stories + test_stories)))\n",
    "    query_maxlen = max(map(len, (x for _, x, _ in train_stories + test_stories)))\n",
    "\n",
    "    word_idx = dict((c, i + 1) for i, c in enumerate(vocab))\n",
    "    inputs_train, queries_train, answers_train = vectorize_stories(train_stories, word_idx, story_maxlen, query_maxlen)\n",
    "    inputs_test, queries_test, answers_test = vectorize_stories(test_stories, word_idx, story_maxlen, query_maxlen)\n",
    "\n",
    "    model = build_model(story_maxlen, query_maxlen, vocab_size)\n",
    "\n",
    "    history = model.fit([inputs_train, queries_train], answers_train,\n",
    "          batch_size=32,\n",
    "          epochs=150,\n",
    "          validation_data=([inputs_test, queries_test], answers_test))\n",
    "\n",
    "    histories.append(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 26892
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2419609,
     "status": "ok",
     "timestamp": 1556754722947,
     "user": {
      "displayName": "Hasan Rizvi",
      "photoUrl": "",
      "userId": "12377090762076158584"
     },
     "user_tz": 300
    },
    "id": "f81r-rKfpyEw",
    "outputId": "2954ba7d-4b10-4447-8b8e-f1c089857fef"
   },
   "outputs": [],
   "source": [
    "# Tasks 6 to 10\n",
    "\n",
    "for i in range(6, 11):\n",
    "    challenge = challenges[challenge_type.format(i)]\n",
    "  \n",
    "    print('Extracting stories for the challenge:', challenge_type.format(i))\n",
    "    print(challenge.format(''))\n",
    "  \n",
    "    with tarfile.open(path) as tar:\n",
    "        train_stories = get_stories(tar.extractfile(challenge.format('train')))\n",
    "        test_stories = get_stories(tar.extractfile(challenge.format('test')))\n",
    "\n",
    "    # Building vocabulary\n",
    "    vocab = set()\n",
    "    for story, q, answer in train_stories + test_stories:\n",
    "        vocab |= set(story + q + [answer])\n",
    "    vocab = sorted(vocab)\n",
    "\n",
    "    # Reserve 0 for masking via pad_sequences\n",
    "    vocab_size = len(vocab) + 1\n",
    "    story_maxlen = max(map(len, (x for x, _, _ in train_stories + test_stories)))\n",
    "    query_maxlen = max(map(len, (x for _, x, _ in train_stories + test_stories)))\n",
    "\n",
    "    word_idx = dict((c, i + 1) for i, c in enumerate(vocab))\n",
    "    inputs_train, queries_train, answers_train = vectorize_stories(train_stories, word_idx, story_maxlen, query_maxlen)\n",
    "    inputs_test, queries_test, answers_test = vectorize_stories(test_stories, word_idx, story_maxlen, query_maxlen)\n",
    "\n",
    "    model = build_model(story_maxlen, query_maxlen, vocab_size)\n",
    "\n",
    "    history = model.fit([inputs_train, queries_train], answers_train,\n",
    "          batch_size=32,\n",
    "          epochs=150,\n",
    "          validation_data=([inputs_test, queries_test], answers_test))\n",
    "\n",
    "    histories.append(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 26892
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3586373,
     "status": "ok",
     "timestamp": 1556755891187,
     "user": {
      "displayName": "Hasan Rizvi",
      "photoUrl": "",
      "userId": "12377090762076158584"
     },
     "user_tz": 300
    },
    "id": "PqLpg8aap4Y-",
    "outputId": "9a834151-4383-4f2a-e42e-f57288daa542"
   },
   "outputs": [],
   "source": [
    "# Tasks 11 to 15\n",
    "\n",
    "for i in range(11, 16):\n",
    "    challenge = challenges[challenge_type.format(i)]\n",
    "  \n",
    "    print('Extracting stories for the challenge:', challenge_type.format(i))\n",
    "    print(challenge.format(''))\n",
    "  \n",
    "    with tarfile.open(path) as tar:\n",
    "        train_stories = get_stories(tar.extractfile(challenge.format('train')))\n",
    "        test_stories = get_stories(tar.extractfile(challenge.format('test')))\n",
    "\n",
    "    # Building vocabulary\n",
    "    vocab = set()\n",
    "    for story, q, answer in train_stories + test_stories:\n",
    "        vocab |= set(story + q + [answer])\n",
    "    vocab = sorted(vocab)\n",
    "\n",
    "    # Reserve 0 for masking via pad_sequences\n",
    "    vocab_size = len(vocab) + 1\n",
    "    story_maxlen = max(map(len, (x for x, _, _ in train_stories + test_stories)))\n",
    "    query_maxlen = max(map(len, (x for _, x, _ in train_stories + test_stories)))\n",
    "\n",
    "    word_idx = dict((c, i + 1) for i, c in enumerate(vocab))\n",
    "    inputs_train, queries_train, answers_train = vectorize_stories(train_stories, word_idx, story_maxlen, query_maxlen)\n",
    "    inputs_test, queries_test, answers_test = vectorize_stories(test_stories, word_idx, story_maxlen, query_maxlen)\n",
    "\n",
    "    model = build_model(story_maxlen, query_maxlen, vocab_size)\n",
    "\n",
    "    history = model.fit([inputs_train, queries_train], answers_train,\n",
    "          batch_size=32,\n",
    "          epochs=150,\n",
    "          validation_data=([inputs_test, queries_test], answers_test))\n",
    "\n",
    "    histories.append(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 26892
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 325037,
     "status": "ok",
     "timestamp": 1556757069351,
     "user": {
      "displayName": "Hasan Rizvi",
      "photoUrl": "",
      "userId": "12377090762076158584"
     },
     "user_tz": 300
    },
    "id": "PNrxPmm3qC_f",
    "outputId": "8f08bd25-b7f7-4c0e-a9d1-0871af401291"
   },
   "outputs": [],
   "source": [
    "# Tasks 16 to 20\n",
    "\n",
    "for i in range(16, 21):\n",
    "    challenge = challenges[challenge_type.format(i)]\n",
    "  \n",
    "    print('Extracting stories for the challenge:', challenge_type.format(i))\n",
    "    print(challenge.format(''))\n",
    "  \n",
    "    with tarfile.open(path) as tar:\n",
    "        train_stories = get_stories(tar.extractfile(challenge.format('train')))\n",
    "        test_stories = get_stories(tar.extractfile(challenge.format('test')))\n",
    "\n",
    "    # Building vocabulary\n",
    "    vocab = set()\n",
    "    for story, q, answer in train_stories + test_stories:\n",
    "        vocab |= set(story + q + [answer])\n",
    "    vocab = sorted(vocab)\n",
    "\n",
    "    # Reserve 0 for masking via pad_sequences\n",
    "    vocab_size = len(vocab) + 1\n",
    "    story_maxlen = max(map(len, (x for x, _, _ in train_stories + test_stories)))\n",
    "    query_maxlen = max(map(len, (x for _, x, _ in train_stories + test_stories)))\n",
    "\n",
    "    word_idx = dict((c, i + 1) for i, c in enumerate(vocab))\n",
    "    inputs_train, queries_train, answers_train = vectorize_stories(train_stories, word_idx, story_maxlen, query_maxlen)\n",
    "    inputs_test, queries_test, answers_test = vectorize_stories(test_stories, word_idx, story_maxlen, query_maxlen)\n",
    "\n",
    "    model = build_model(story_maxlen, query_maxlen, vocab_size)\n",
    "\n",
    "    history = model.fit([inputs_train, queries_train], answers_train,\n",
    "          batch_size=32,\n",
    "          epochs=150,\n",
    "          validation_data=([inputs_test, queries_test], answers_test))\n",
    "\n",
    "    histories.append(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "70M4qDNEFsOI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1279
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4396,
     "status": "ok",
     "timestamp": 1556758519831,
     "user": {
      "displayName": "Hasan Rizvi",
      "photoUrl": "",
      "userId": "12377090762076158584"
     },
     "user_tz": 300
    },
    "id": "H5ZffCfepSae",
    "outputId": "92ff8aa6-40d5-4fbc-b661-f8941a702452"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(5, 4, sharex='col', sharey='row')\n",
    "fig.suptitle('Accuracies')\n",
    "count = 0\n",
    "fig.set_figheight(20)\n",
    "fig.set_figwidth(20)\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(4):\n",
    "    \n",
    "        cur_ax = ax[i, j]\n",
    "\n",
    "        cur_ax.set_ylim([0, 1])\n",
    "\n",
    "        cur_ax.figsize = (10,10)\n",
    "        cur_ax.plot(histories[count].history['acc'][:40])\n",
    "        cur_ax.plot(histories[count].history['val_acc'][:40])\n",
    "        cur_ax.set_title('Task {}'.format(count + 1))\n",
    "        cur_ax.legend(['train', 'test'], loc='upper left')\n",
    "        count += 1\n",
    "\n",
    "fig.savefig('accuracies.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1278
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4701,
     "status": "ok",
     "timestamp": 1556759006324,
     "user": {
      "displayName": "Hasan Rizvi",
      "photoUrl": "",
      "userId": "12377090762076158584"
     },
     "user_tz": 300
    },
    "id": "Ixd4UQOEDZga",
    "outputId": "3c3a453b-f73a-4118-f19a-b71366389699"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(5, 4, sharex='col', sharey='none')\n",
    "fig.suptitle('Losses')\n",
    "count = 0\n",
    "fig.set_figheight(20)\n",
    "fig.set_figwidth(20)\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(4):\n",
    "\n",
    "        cur_ax = ax[i, j]\n",
    "\n",
    "        cur_ax.figsize = (10,10)\n",
    "        cur_ax.plot(histories[count].history['loss'][:40])\n",
    "        cur_ax.plot(histories[count].history['val_loss'][:40])\n",
    "        cur_ax.set_title('Task {}'.format(count + 1))\n",
    "        cur_ax.legend(['train', 'test'], loc='upper left')\n",
    "        count += 1\n",
    "\n",
    "fig.savefig('losses.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MWmASd_CzzDS"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download('accuracies.png')\n",
    "files.download('losses.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 699,
     "status": "ok",
     "timestamp": 1556758847219,
     "user": {
      "displayName": "Hasan Rizvi",
      "photoUrl": "",
      "userId": "12377090762076158584"
     },
     "user_tz": 300
    },
    "id": "AtqqT7jtDoee",
    "outputId": "3b2f827a-ee1b-4d31-dfe9-dede7c416a23"
   },
   "outputs": [],
   "source": [
    "histories[9].history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 664
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 408,
     "status": "ok",
     "timestamp": 1556668102119,
     "user": {
      "displayName": "Hasan Rizvi",
      "photoUrl": "",
      "userId": "12377090762076158584"
     },
     "user_tz": 300
    },
    "id": "Afv4CDwgFsOb",
    "outputId": "c6367654-c5c5-4ea6-e086-b4b059ead844"
   },
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "SVG(model_to_dot(MemN2Nmodel).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 405,
     "status": "ok",
     "timestamp": 1556668106512,
     "user": {
      "displayName": "Hasan Rizvi",
      "photoUrl": "",
      "userId": "12377090762076158584"
     },
     "user_tz": 300
    },
    "id": "ilmU3KBgFsOe",
    "outputId": "95a48034-775d-4cf0-9189-273b8e165f0a"
   },
   "outputs": [],
   "source": [
    "model = MemN2Nmodel\n",
    "import matplotlib.pyplot as plt\n",
    "# summarize history for accuracy\n",
    "plt.plot(model.history.history['acc'][:200])\n",
    "plt.plot(model.history.history['val_acc'][:200])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 435,
     "status": "ok",
     "timestamp": 1556668116596,
     "user": {
      "displayName": "Hasan Rizvi",
      "photoUrl": "",
      "userId": "12377090762076158584"
     },
     "user_tz": 300
    },
    "id": "EiVeXMDIFsOh",
    "outputId": "19660fc6-ab16-498e-8e04-bced3282de70"
   },
   "outputs": [],
   "source": [
    "model = MemN2Nmodel\n",
    "import matplotlib.pyplot as plt\n",
    "# summarize history for accuracy\n",
    "plt.plot(model.history.history['loss'][:200])\n",
    "plt.plot(model.history.history['val_loss'][:200])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 277,
     "status": "ok",
     "timestamp": 1556658883062,
     "user": {
      "displayName": "Hasan Rizvi",
      "photoUrl": "",
      "userId": "12377090762076158584"
     },
     "user_tz": 300
    },
    "id": "Bxh0UhPqFsOl",
    "outputId": "876207f0-e599-4267-8483-bf9ccb851f87"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WuYXjgv2tRaU"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "bAbi_independently_trained.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
